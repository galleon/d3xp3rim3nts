{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConnectX.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galleon/d3xp3rim3nts/blob/master/ConnectX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ-bzP71ICIq",
        "colab_type": "code",
        "outputId": "4b343cbd-7450-47b7-a0fe-ee91f760ee83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class state:\n",
        "  def is_end_state():\n",
        "    return True\n",
        "  def possible_moves():\n",
        "    return []\n",
        "\n",
        "class connectX:\n",
        "  def __init__(self, nrows=6, ncols=7, inrow=4, player1, player2, exp1=1, exp2=1, tag1=1, tag2=2):\n",
        "    self.nrows = nrows\n",
        "    self.ncols = ncols\n",
        "    self.inrow = inrow\n",
        "    self.state, self.winner, self.turn = self.init_game()\n",
        "    self.players = {1: player1(tag1, exploration_factor=exp1), \n",
        "                    2: player2(tag2, exploration_factor=exp2)}\n",
        "    self.memory = {}\n",
        "\n",
        "  def init_game(self):\n",
        "    return np.zeros((self.nrows, self.ncols)), None, 1\n",
        "\n",
        "  def next_player(self):\n",
        "    if self.turn == 1:\n",
        "      self.turn = 2\n",
        "    else:\n",
        "      self.turn = 1\n",
        "\n",
        "  def game_winner(self):\n",
        "    for i in range(len(self.state[:, 0])-xxxx):\n",
        "      for j in range(len(self.state[0, :])-):\n",
        "        self.square_winner()\n",
        "        if self.winner is not None:\n",
        "\n",
        "  def square_winner(self, square):\n",
        "    s = np.append([np.sum(sqare, axis=0), np.sum(square, axis=1).T],\n",
        "                  [np.trace(square), np.flip(square, axis=1).trace()])\n",
        "    if np.max(s) == self.inrow:\n",
        "      self.winner = 1\n",
        "    elif np.min(s) == -self.inrow:\n",
        "      self.winner = 2\n",
        "    else:\n",
        "      self.winner = None\n",
        "    return self.winner\n",
        "  \n",
        "  def play_game(self, learn=False):\n",
        "    move_count = 0\n",
        "    while self.winner == None:\n",
        "      move = self.play_move(learn)\n",
        "      self.state = self.make_state_from_move(move)\n",
        "      self.game_winner()\n",
        "      self.next_player()\n",
        "      move_count += 1\n",
        "\n",
        "    self.play_move(learn)\n",
        "    self.next_player()\n",
        "    self.play_move(learn)\n",
        "    self.next_player()\n",
        "\n",
        "    return self.winner, move_count\n",
        "  \n",
        "  def play_move(self, learn):\n",
        "    player = self.players[self.turn]\n",
        "    move = player.choose_move(self.state, self.winner, learn)\n",
        "    return move\n",
        "\n",
        "  def play_multiple_games(self, episodes, learn):\n",
        "    statistics = {1: 0, 2: 0, 0: 0, 'move_count': 0}\n",
        "    move_count_total = []\n",
        "    for i in range(episodes):\n",
        "        winner, move_count = self.play_game(learn)\n",
        "        move_count_total.append(move_count)\n",
        "        statistics[winner] = statistics[winner] + 1\n",
        "\n",
        "        self.state, self.winner, self.turn = self.init_game()\n",
        "\n",
        "    if isinstance(self.players[1], TicRLAgent):\n",
        "      self.players[1].save_values()\n",
        "    if isinstance(self.players[2], TicRLAgent):\n",
        "      self.players[2].save_values()\n",
        "\n",
        "    if learn is True and isinstance(self.players[1], MCTSAgent):\n",
        "      self.players[1].save_tree()\n",
        "    if learn is True and isinstance(self.players[2], MCTSAgent):\n",
        "      self.players[2].save_tree()\n",
        "\n",
        "    statistics['move_count'] = np.mean(move_count_total)\n",
        "    return statistics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a3855cf28c37>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    for j in range(len(self.state[0, :])-):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-vhwvNeoVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episodes = 300\n",
        "\n",
        "game = connectX(6, 7, DQNAgent, MCTSAgent, 0.8, 0.8)\n",
        "statistics = game.play_multiple_games(episodes, learn=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1itdZMf1n4_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "  def __init__(self, tag, exploration_factor=1):\n",
        "    self.tag = tag\n",
        "    self.exp_factor = exploration_factor\n",
        "\n",
        "  def choose_move(self, state, winner, learn):\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1O_RT7go6rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MCTSAgent:\n",
        "  def __init__(self, tag, exploration_factor=1):\n",
        "    self.tag = tag\n",
        "    self.exp_factor = exploration_factor\n",
        "    global t\n",
        "    global con_tree\n",
        "\n",
        "  def choose_move(self, state, winner, learn):\n",
        "\n",
        "  def expand_opp_move(self, state, learn):\n",
        "    if self.exp_factor == 0 or self.expand_flag is False:\n",
        "      return\n",
        "\n",
        "    prev_state = \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1WHBrhlIOVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minimax(state, max_depth, is_player_minimizer):\n",
        "  if max_depth == 0 or state.is_end_state():\n",
        "    return evaluation_function(state)\n",
        "  if is_player_minimizer:\n",
        "    value = -math.inf\n",
        "    for move in state.possible_moves():\n",
        "      evaluation = minimax(move, max_depth - 1, False)\n",
        "      min = min(value, evaluation)\n",
        "    return value\n",
        "  value = math.inf\n",
        "  for move in state.possible_moves():\n",
        "    evaluation = minimax(move, max_depth - 1, True)\n",
        "    max = max(value, evaluation)\n",
        "  return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Lcd39eWcs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def agent(observation, configuration):\n",
        "    # Number of Columns on the Board.\n",
        "    columns = configuration.columns\n",
        "    # Number of Rows on the Board.\n",
        "    rows = configuration.rows\n",
        "    # Number of Checkers \"in a row\" needed to win.\n",
        "    inarow = configuration.inarow\n",
        "    # The current serialized Board (rows x columns).\n",
        "    board = observation.board\n",
        "    # Which player the agent is playing as (1 or 2).\n",
        "    mark = observation.mark\n",
        "\n",
        "    # Return which column to drop a checker (action).\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWqcMAE7J44t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minimax(state, max_depth, is_player_minimizer, alpha, beta):\n",
        "  if max_depth == 0 or state.is_end_state():\n",
        "    return evaluation_function(state)\n",
        "  if is_player_minimizer:\n",
        "    value = -math.inf\n",
        "    for move in state.possible_moves():\n",
        "      evaluation = minimax(move, max_depth - 1, False, alpha , beta)\n",
        "      min = min(value, evaluation)\n",
        "      beta = min(beta, evaluation)\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "      return value  \n",
        "  value = math.inf\n",
        "  for move in state.possible_moves():\n",
        "    evaluation = minimax(move, max_depth - 1, True, alpha, beta)\n",
        "    max = max(value, evaluation)\n",
        "    alpha = max(alpha, evaluation)\n",
        "    if beta <= alpha:\n",
        "      break\n",
        "    return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHXxpy9J7IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}